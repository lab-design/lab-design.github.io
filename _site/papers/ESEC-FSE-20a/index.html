<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags always come first -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/design.css">
    <link rel="icon" href="/favicon.ico">
    <title>Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness</title>
  </head>

  <body>
    <!-- Load jQuery before the content in order to support the papers page sorting -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>

    <header>

  <div class="brand-bg-color">
    <div class="container">
      <div class="brand-navbar">
        <div class="row">
          <div class="flex-separate col-12">
            <a href="/" class="nav-link">
              <span id="isu-logo">Iowa State University</span>
              <span class="d-none d-sm-block">Laboratory for Software Design</span>
              <span class="small d-block d-sm-none">Laboratory for Software Design</span>
            </a>
            <button class="navbar-toggler d-block d-sm-none" type="button" data-toggle="collapse" data-target="#collapseNav">&#9776;</button>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="nav-bg-color">
    <nav class="container navbar navbar-dark navbar-expand-sm">
      <div class="collapse navbar-collapse" id="collapseNav">
        <div class="navbar-nav">
          <a class="nav-item nav-link" href="/projects.html">Projects</a>
          <a class="nav-item nav-link" href="/papers/">Papers</a>
          <a class="nav-item nav-link" href="/grants/">Grants</a>
          <a class="nav-item nav-link" href="/news/">News</a>
          <a class="nav-item nav-link" href="/people.html">People</a>
          <a class="nav-item nav-link" href="/about/">About</a>
        </div>
      </div>
    </nav>
  </div>

</header>


<main class="container">
  <br />
  <div class="row">
  <div class="col-12">
    <h2 class="page-title">Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness</h2>
    

<h4>
By: 
Sumon Biswas and Hridesh Rajan

</h4>


<a href="ml-fairness.pdf" class="icon">
  <img src="/img/pdf_icon.svg"/ alt="PDF Download">
  <span>Download Paper</span>
</a>

<br/>



<h4>Abstract</h4>
<p>
  <span id="biswas20machine">
    Machine learning models are increasingly being used in important
    decision-making software such as approving bank loans, recommending
    criminal sentencing, hiring employees, and so on. It is important to
    ensure the fairness of these models so that no discrimination is made
    based on protected attribute (e.g., race, sex, age) while decision making.
    Algorithms have been developed to measure unfairness and mitigate them to
    a certain extent. In this paper, we have focused on the empirical
    evaluation of fairness and mitigations on real-world machine learning
    models. We have created a benchmark of 40 top-rated models from Kaggle
    used for 5 different tasks, and then using a comprehensive set of fairness
    metrics, evaluated their fairness. Then, we have applied 7 mitigation
    techniques on these models and analyzed the fairness, mitigation results,
    and impacts on performance. We have found that some model optimization
    techniques result in inducing unfairness in the models. On the other hand,
    although there are some fairness control mechanisms in machine learning
    libraries, they are not documented. The mitigation algorithm also exhibit
    common patterns such as mitigation in the post-processing is often costly
    (in terms of performance) and mitigation in the pre-processing stage is
    preferred in most cases. We have also presented different trade-off
    choices of fairness mitigation decisions. Our study suggests future
    research directions to reduce the gap between theoretical fairness aware
    algorithms and the software engineering methods to leverage them in practice.
  </span>
</p>





<h4>ACM Reference</h4>
<p>
<span id="biswas20machine">Biswas, S. and Rajan, H. 2020. Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness. <i>ESEC/FSEâ€™2020: The 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</i> (Nov. 2020).</span>
</p>

<h4>BibTeX Reference</h4>
<pre><code>@inproceedings{biswas20machine,
  author = {Sumon Biswas and Hridesh Rajan},
  title = {Do the Machine Learning Models on a Crowd Sourced Platform Exhibit Bias? An Empirical Study on Model Fairness},
  booktitle = {ESEC/FSE'2020: The 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  location = {Sacramento, California, United States},
  month = {November 8-November 13, 2020},
  year = {2020},
  entrysubtype = {conference},
  abstract = {
    Machine learning models are increasingly being used in important
    decision-making software such as approving bank loans, recommending
    criminal sentencing, hiring employees, and so on. It is important to
    ensure the fairness of these models so that no discrimination is made
    based on protected attribute (e.g., race, sex, age) while decision making.
    Algorithms have been developed to measure unfairness and mitigate them to
    a certain extent. In this paper, we have focused on the empirical
    evaluation of fairness and mitigations on real-world machine learning
    models. We have created a benchmark of 40 top-rated models from Kaggle
    used for 5 different tasks, and then using a comprehensive set of fairness
    metrics, evaluated their fairness. Then, we have applied 7 mitigation
    techniques on these models and analyzed the fairness, mitigation results,
    and impacts on performance. We have found that some model optimization
    techniques result in inducing unfairness in the models. On the other hand,
    although there are some fairness control mechanisms in machine learning
    libraries, they are not documented. The mitigation algorithm also exhibit
    common patterns such as mitigation in the post-processing is often costly
    (in terms of performance) and mitigation in the pre-processing stage is
    preferred in most cases. We have also presented different trade-off
    choices of fairness mitigation decisions. Our study suggests future
    research directions to reduce the gap between theoretical fairness aware
    algorithms and the software engineering methods to leverage them in practice.
  }
}
</code></pre>


  </div>
  </div>
  <br />
</main>


<footer>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      },
      i[r].l = 1 * new Date();
      a = s.createElement(o),
      m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-512574-3', 'auto');
    ga('send', 'pageview');
  </script>
  <div class="container">
    <div>
      <div class="row">
        <div class="col-12">
          <div class="row">
            <div class="col-xs-12 col-lg-3 isu-logo-wrapper">
              <a href="http://www.iastate.edu">
                <img src="/img/isu-stacked.svg" alt="Iowa State University" class="isu-logo">
              </a>
            </div>
            <div class="col-xs-12 col-sm-6 col-md-5 col-lg-4">
              <p>
                <b>Laboratory for Software Design</b>
              </p>
              <p>115-2 Atanasoff Hall</p>
              <p>Ames, IA, 50011-1040, USA</p>
              <p>Phone: (515) 294-6168</p>
              <p>E-Mail: hridesh@iastate.edu</p>
            </div>
            <div class="col-xs-12 col-sm-6 col-md-4 col-lg-4">
              <p>
                Copyright &copy;
                2021
                Iowa State University of Science and Technology. All rights reserved.<BR>
                <div class="d-none d-lg-block" style="margin-top: 0">
                  The research and educational activities described on these pages has been supported in part by the
                  <a href="http://www.nsf.gov">US National Science Foundation (NSF)</a>.
                </div>
              </p>
            </div>
            <div class="col-md-3 col-lg-1 d-none d-md-block project-logos">
              <div>
                <a href="http://web.cs.iastate.edu/~panini/">
                  <img src="/img/panini-logo.svg" class="logo" alt="Boa Logo">
                  Panini
                </div>
                <div>
                  <a href="http://boa.cs.iastate.edu">
                    <img src="/img/boa-logo.svg" class="logo" alt="Boa Logo">
                    Boa
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>



    <!-- jQuery first, then Tether, then Bootstrap JS. -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js" integrity="sha384-Plbmg8JY28KFelvJVai01l8WyZzrYWG825m+cZ0eDDS1f7d/js6ikvy1+X+guPIB" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
    <script src="/js/design.js"></script>
  </body>
</html>
