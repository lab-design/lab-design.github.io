<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags always come first -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/design.css">
    <link rel="icon" href="/favicon.ico">
    <title>Sumon Biswas defends Ph.D. thesis</title>
  </head>

  <body>
    <!-- Load jQuery before the content in order to support the papers page sorting -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>

    <header>
  <div class="brand-bg-color">
    <div class="container">
      <div class="brand-navbar">
        <div class="row">
          <div class="flex-separate col-12 d-flex justify-content-between align-items-center">
            <a href="/" class="nav-link">
              <img src="/img/tulane-sse-logo.png" alt="Tulane School of Science and Engineering" id="header-logo"
                   style="height: 60px; margin: 10px 0; padding: 5px; border-radius: 4px;"/>
            </a>
            <!-- Navbar toggle button for mobile -->
            <button class="navbar-toggler d-block d-sm-none" type="button" data-toggle="collapse" data-target="#collapseNav" aria-controls="collapseNav" aria-expanded="false" aria-label="Toggle navigation">
              &#9776;
            </button>
            <!-- Desktop navigation links -->
            <div class="navbar-nav nav-horizontal d-none d-sm-flex">
              <a class="nav-item nav-link" href="/projects.html">Projects</a>
              <a class="nav-item nav-link" href="/papers/">Papers</a>
              <a class="nav-item nav-link" href="/grants/">Grants</a>
              <a class="nav-item nav-link" href="/news/">News</a>
              <a class="nav-item nav-link" href="/people.html">People</a>
              <a class="nav-item nav-link" href="/about/">About</a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Mobile navigation menu (only shows when collapsed) -->
  <div class="nav-bg-color d-sm-none">
    <nav class="container navbar navbar-dark navbar-expand-sm">
      <div class="collapse navbar-collapse" id="collapseNav">
        <div class="navbar-nav">
          <a class="nav-item nav-link" href="/projects.html">Projects</a>
          <a class="nav-item nav-link" href="/papers/">Papers</a>
          <a class="nav-item nav-link" href="/grants/">Grants</a>
          <a class="nav-item nav-link" href="/news/">News</a>
          <a class="nav-item nav-link" href="/people.html">People</a>
          <a class="nav-item nav-link" href="/about/">About</a>
        </div>
      </div>
    </nav>
  </div>
</header>

<main class="container">
  <br />
  <div class="row">
  <div class="col-12">
    <h2 class="page-title">Sumon Biswas defends Ph.D. thesis</h2>
    <p class="mb-2 text-muted">April 13, 2022</p>

  <span class="news-link">Links: </span>
  
    <a href="https://www.cs.iastate.edu/phd-final-oral-exam-sumon-biswas" class="news-link">Event Link</a>
    
  

<p>Sumon Biswas has successfully defended his Ph.D. thesis entitled
“<em>Understanding and Reasoning Fairness in Machine Learning Pipelines</em>”. His research unravels several software engineering techniques towards ethical AI, which has been an area of concern in the recent past.
The abstract of the thesis is as follows:</p>

<p><em>
``Machine learning (ML) algorithms are increasingly being used in critical decision making software such as criminal sentencing, hiring employees, approving bank loans, college admission systems, which affect human lives directly. Algorithmic fairness of these ML based software has become a major concern in the recent past. Many incidents have been reported where ML models discriminated people based on their protected attributes e.g., race, sex, age, religious belief, etc. Research has been conducted to test and mitigate unfairness in ML models. However, there is a large gap between the theory of ML fairness and how the property can be ensured in practice. Similar to analyzing traditional software defects, fairness has to be engineered in ML software to minimize and eventually guarantee bias-free decisions. In this dissertation, we are the first to introduce compositional reasoning of group fairness in ML pipeline and propose individual fairness verification technique for neural networks. Towards that goal, first, we conducted a large-scale empirical study to understand unfairness issues in open-source ML models. A number of definitions of algorithmic fairness have been proposed in the literature and many bias mitigation techniques have been proposed. Group fairness property ensures that the protected groups (e.g., male-vs-female, young-vs-old, etc.) get similar treatment in the prediction. On the other hand, individual fairness states that any two similar individuals should be predicted similarly irrespective of their protected attributes. Often an accuracy-fairness tradeoff is experienced when a mitigation algorithm is applied. We evaluated fairness of models collected from Kaggle and investigated their root causes, compared the performance of mitigation algorithms and their impacts on accuracy.</em></p>

<p>For ML tasks, it is a common practice to build a pipeline that includes an ordered set of stages from acquisition, to preprocessing, to modeling, and so on. However, no research has been conducted to measure fairness of a specific stage or data transformer operators in the pipeline. The existing metrics measure the fairness of the pipeline holistically. We proposed causal reasoning in ML pipeline to measure and instrument fairness of data preprocessing stages. We leveraged existing metrics to define component-specific fairness and localize fairness issues in the pipeline. We also showed how the local fairness of a preprocessing stage composes in the global fairness of the pipeline. In addition, we used the fairness composition to choose appropriate downstream transformer that mitigates unfairness. Although we could identify and localize unfairness in the ML model, providing formal guarantees of fairness is challenging because of the complex decision-making process. Therefore, we proposed Fairify, an approach to verify individual fairness property in neural networks (NN). Fairify leverages white-box access and neural pruning to provide certification or counterexample. The key idea is that many neurons in the NN always remain inactive for certain smaller parts of the input domain. So, Fairify applies input partitioning and then prunes the NN for each partition to make them amenable to verification. In this work, we proposed the first SMT-based fairness verification that can answer targeted fairness queries with relaxations as well as provide counterexamples.’’&lt;/EM&gt;</p>

<p>Biswas’s MS theis committee consisted of Hridesh Rajan (major professor), Wei Le, Andrew Miner, Simanta Mitra, and Kevin Liu.</p>

<p>Congratulations, Sumon Biswas!</p>



  </div>
  </div>
  <br />
</main>


<footer>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      },
      i[r].l = 1 * new Date();
      a = s.createElement(o),
      m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-512574-3', 'auto');
    ga('send', 'pageview');
  </script>
  <div class="container">
    <div>
      <div class="row">
        <div class="col-12">
          <div class="row">
            <div class="col-xs-12 col-lg-3 tulane-logo-wrapper">
              <a href="http://www.iastate.edu">
                <img src="/img/tulane-logo.png" alt="Tulane University" class="tulane-logo">
              </a>
            </div>
            <div class="col-xs-12 col-sm-6 col-md-5 col-lg-4">
              <p>
                <b>Laboratory for Software Design</b>
              </p>
              <p>201 Lindy Claiborne Boggs Center</p>
              <p>6823 St. Charles Avenue</p>
              <p>New Orleans, LA 70118-5698</p>
              <p>Phone: (504) 865-5764</p>
              <p>E-Mail: hrajan@tulane.edu</p>
            </div>
            <div class="col-xs-12 col-sm-6 col-md-4 col-lg-4">
              <p>
              Copyright &copy;
              2025
              Tulane University. All rights reserved.
                <div class="d-none d-lg-block" style="margin-top: 0">
                  The research and educational activities described on these pages has been supported in part by the
                  <a href="http://www.nsf.gov">US National Science Foundation (NSF)</a>.
                </div>
              </p>
            </div>
            <div class="col-md-3 col-lg-1 d-none d-md-block project-logos">
              <div>
                <a href="http://web.cs.iastate.edu/~panini/">
                  <img src="/img/panini-logo.svg" class="logo" alt="Boa Logo">
                  Panini
                </div>
                <div>
                  <a href="http://boa.cs.iastate.edu">
                    <img src="/img/boa-logo.svg" class="logo" alt="Boa Logo">
                    Boa
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>



    <!-- jQuery first, then Tether, then Bootstrap JS. -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.2.0/js/tether.min.js" integrity="sha384-Plbmg8JY28KFelvJVai01l8WyZzrYWG825m+cZ0eDDS1f7d/js6ikvy1+X+guPIB" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
    <script src="/js/design.js"></script>
  </body>
</html>
